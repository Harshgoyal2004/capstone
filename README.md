<![CDATA[<div align="center">

# ğŸ¥ AI Health Screening Assistant

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-3776AB?logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-%3E%3D2.0-EE4C2C?logo=pytorch&logoColor=white)](https://pytorch.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688?logo=fastapi&logoColor=white)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.38-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io)
[![Gemini](https://img.shields.io/badge/Google%20Gemini-LLM-4285F4?logo=google&logoColor=white)](https://ai.google.dev)
[![License: Educational](https://img.shields.io/badge/License-Educational%20%26%20Research-blue)](#license)

**A conversational health screening platform integrating pretrained PyTorch deep learning models with a Google Gemini LLM chat interface for cardiac, metabolic, and motor risk assessment.**

[Getting Started](#-quick-start) Â· [Model Details](#-ml-model-specifications) Â· [API Reference](#-api-reference) Â· [Demo](#-demo--sample-test-files)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#-key-features)
- [System Architecture](#system-architecture)
- [Technology Stack](#technology-stack)
- [ML Model Specifications](#-ml-model-specifications)
  - [Heart Arrhythmia Model (ECGNet)](#1-heart-arrhythmia-model-ecgnet)
  - [Diabetes Risk Model (DiabetesNet)](#2-diabetes-risk-model-diabetesnet)
  - [Parkinson's Voice Risk Model (ParkinsonNet)](#3-parkinsons-voice-risk-model-parkinsonnet)
- [LLM Integration & Prompt Engineering](#-llm-integration--prompt-engineering)
- [System Flow](#system-flow)
- [Project Structure](#project-structure)
- [Quick Start](#-quick-start)
- [Demo & Sample Test Files](#-demo--sample-test-files)
- [Usage Guide](#usage-guide)
- [API Reference](#-api-reference)
- [Data Collection Protocol](#data-collection-protocol)
- [Risk Assessment & Triage](#risk-assessment--triage)
- [Signal Processing Deep Dive](#-signal-processing-deep-dive)
- [Research Papers](#-research-papers)
- [Future Improvements](#-future-improvements)
- [Limitations & Disclaimer](#limitations--disclaimer)
- [Acknowledgments](#acknowledgments)

---

## Overview

This application provides a preliminary health screening experience through natural conversation. A user chats with an AI assistant powered by Google Gemini, which conducts a structured medical intake interview. Once all required data is collected, three pretrained PyTorch models simultaneously analyze:

| Screening Domain | Model | Input Data |
|:---|:---|:---|
| **ğŸ’“ Cardiac Risk** | ECGNet (Multi-Scale Attention CNN) | Uploaded ECG waveform (.csv) |
| **ğŸ©¸ Metabolic Risk** | DiabetesNet (Tabular DNN) | 8 clinical biomarkers collected via conversation |
| **ğŸ§  Motor Risk** | ParkinsonNet (Tabular DNN) | Uploaded voice recording (.wav) |

The LLM then explains the screening results in clear, empathetic language â€” **without diagnosing or claiming any medical conditions**.

> ğŸ’¡ **How it works**: Gemini collects data conversationally â†’ the backend intercepts a structured `<MODEL_INPUT>` tag â†’ runs all 3 PyTorch models â†’ feeds a `<MODEL_OUTPUT>` back to Gemini â†’ Gemini explains results to the patient.

---

## âœ¨ Key Features

- **ğŸ—¨ï¸ Conversational Medical Intake** â€” Natural language health data collection via Gemini LLM, asking 2â€“3 questions at a time
- **ğŸ§  Multi-Model Inference** â€” Three independent PyTorch neural networks running simultaneously for cardiac, metabolic, and motor assessment
- **ğŸ“Š Automated Triage** â€” Rule-based triage classification (routine / recommended check / priority review) based on combined risk levels
- **ğŸ“ File-Based Analysis** â€” Direct upload and inference on ECG waveforms (.csv) and voice recordings (.wav)
- **ğŸ”„ LLM Fallback Chain** â€” Automatic model rotation (gemini-1.5-flash â†’ gemini-1.5-pro â†’ gemini-2.0-flash) on rate limits
- **âš•ï¸ Medical Safety Guardrails** â€” System prompt enforces screening-only language; never diagnoses, always recommends professional consultation
- **ğŸ¨ Polished UI** â€” Gradient header, risk badges, real-time screening status tracking, and disclaimer overlay

---

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        STREAMLIT FRONTEND                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Chat UI     â”‚  â”‚  File Uploads    â”‚  â”‚  Results Display     â”‚  â”‚
â”‚  â”‚  (st.chat)   â”‚  â”‚  ECG (.csv)      â”‚  â”‚  Risk badges         â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  Voice (.wav)    â”‚  â”‚  Triage level        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚  HTTP             â”‚  HTTP POST /upload
          â”‚  POST /chat       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        FASTAPI BACKEND                              â”‚
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Gemini LLM â”‚â—„â”€â”€â–ºâ”‚        Orchestration Engine               â”‚   â”‚
â”‚  â”‚  (Chat)     â”‚    â”‚  1. Forward msgs to LLM                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  2. Detect <MODEL_INPUT> in response     â”‚   â”‚
â”‚                     â”‚  3. Parse features                        â”‚   â”‚
â”‚                     â”‚  4. Run 3 PyTorch models                  â”‚   â”‚
â”‚                     â”‚  5. Build <MODEL_OUTPUT>                   â”‚   â”‚
â”‚                     â”‚  6. Send results to LLM for explanation   â”‚   â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚          â”‚          â”‚                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Parser Module  â”‚ â”‚ ECGNet  â”‚ â”‚Diabetes â”‚ â”‚ ParkinsonNetâ”‚      â”‚
â”‚  â”‚  MODEL_INPUT/   â”‚ â”‚  Heart  â”‚ â”‚   Net   â”‚ â”‚   Voice     â”‚      â”‚
â”‚  â”‚  MODEL_OUTPUT   â”‚ â”‚  Model  â”‚ â”‚  Model  â”‚ â”‚   Model     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Two-Pass LLM Architecture

The backend uses a unique **double-pass LLM pattern**:

| Pass | Purpose | Trigger |
|:----:|---------|---------|
| **1st** | Gemini collects patient data and outputs `<MODEL_INPUT>` | User provides all required information |
| â€” | Backend intercepts, parses, runs PyTorch inference | `<MODEL_INPUT>` detected in LLM output |
| **2nd** | Gemini receives `<MODEL_OUTPUT>` with real probabilities and explains results | Inference complete |

This ensures the **LLM never fabricates the risk assessments** â€” it only interprets the actual PyTorch model predictions.

---

## Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------| 
| **Frontend** | Streamlit 1.38 | Chat interface, file uploads, real-time results display |
| **Backend** | FastAPI 0.115 + Uvicorn | REST API, orchestration, model inference, file handling |
| **LLM** | Google Gemini (1.5-flash / 1.5-pro / 2.0-flash) | Conversational medical intake & result explanation |
| **ML Framework** | PyTorch â‰¥ 2.0 | Deep learning model inference (CPU/CUDA) |
| **Signal Processing** | SciPy 1.10+ | ECG bandpass filtering (Butterworth), R-peak detection |
| **Audio Analysis** | librosa 0.10+ / soundfile | F0 estimation (pYIN), RMS, harmonic separation, feature extraction |
| **Data Handling** | pandas, NumPy | CSV parsing, feature normalization, array operations |
| **API Client** | google-generativeai | Gemini API interactions with retry logic |
| **Language** | Python 3.10+ | All components |

---

## ğŸ”¬ ML Model Specifications

### 1. Heart Arrhythmia Model (ECGNet)

#### Dataset
- **Source**: [MIT-BIH Arrhythmia Database](https://physionet.org/content/mitdb/1.0.0/) (PhysioNet)
- **Records**: 48 half-hour dual-lead ambulatory ECG recordings from 47 subjects
- **Sampling Rate**: 360 Hz
- **Split**: 28 records for training, 19 records for testing
- **Annotation Standard**: AAMI (Association for the Advancement of Medical Instrumentation)

#### Preprocessing Pipeline
1. **Bandpass filtering**: Butterworth 4th-order, 0.5â€“40 Hz passband (removes baseline wander + high-freq noise)
2. **R-peak detection**: `scipy.signal.find_peaks` with minimum distance 0.5s and adaptive height threshold (`mean + 0.5 Ã— std`)
3. **Beat segmentation**: R-peak centered windows (**108 samples pre-R + 144 samples post-R = 252 samples per beat**)
4. **AAMI beat classification mapping**:

| AAMI Class | Original Symbols | Description |
|:----------:|:----------------:|-------------|
| **N** | N, L, R, e, j | Normal / Bundle branch block |
| **S** | A, a, J, S | Supraventricular ectopic |
| **V** | V, E | Ventricular ectopic |
| **F** | F | Fusion beat |
| **Q** | /, f, Q | Paced / Unknown |

5. **Class balancing**: WeightedRandomSampler for handling severe class imbalance (~72% N-class dominance)

#### Architecture â€” Multi-Scale Attention CNN

```
Input: (batch, 1, 252) â€” single-channel ECG beat
  â”‚
  â”œâ”€â–º MultiScaleBlock 1
  â”‚     â”œâ”€â–º Conv1d(1â†’32, k=3, pad=1)  â”€â”
  â”‚     â”œâ”€â–º Conv1d(1â†’32, k=5, pad=2)  â”€â”¼â”€â–º Concat â†’ BN(96) â†’ ReLU â†’ ChannelAttention(96)
  â”‚     â””â”€â–º Conv1d(1â†’32, k=7, pad=3)  â”€â”˜
  â”‚   â†’ MaxPool1d(2)                                                  â†’ (batch, 96, 126)
  â”‚
  â”œâ”€â–º MultiScaleBlock 2
  â”‚     â”œâ”€â–º Conv1d(96â†’64, k=3, pad=1)  â”€â”
  â”‚     â”œâ”€â–º Conv1d(96â†’64, k=5, pad=2)  â”€â”¼â”€â–º Concat â†’ BN(192) â†’ ReLU â†’ ChannelAttention(192)
  â”‚     â””â”€â–º Conv1d(96â†’64, k=7, pad=3)  â”€â”˜
  â”‚   â†’ MaxPool1d(2)                                                  â†’ (batch, 192, 63)
  â”‚
  â”œâ”€â–º MultiScaleBlock 3
  â”‚     â”œâ”€â–º Conv1d(192â†’128, k=3, pad=1) â”€â”
  â”‚     â”œâ”€â–º Conv1d(192â†’128, k=5, pad=2) â”€â”¼â”€â–º Concat â†’ BN(384) â†’ ReLU â†’ ChannelAttention(384)
  â”‚     â””â”€â–º Conv1d(192â†’128, k=7, pad=3) â”€â”˜
  â”‚                                                                    â†’ (batch, 384, 63)
  â”œâ”€â–º AdaptiveAvgPool1d(1) â†’ squeeze                                  â†’ (batch, 384)
  â””â”€â–º Linear(384 â†’ 5)                                                 â†’ 5-class logits
```

**ChannelAttention(C)** â€” Squeeze-and-Excitation style:
```
Input: (batch, C, T)
  â†’ AdaptiveAvgPool1d(1)        â†’ (batch, C, 1) â†’ squeeze â†’ (batch, C)
  â†’ Linear(C â†’ C/8) â†’ ReLU
  â†’ Linear(C/8 â†’ C) â†’ Sigmoid  â†’ channel weights
  â†’ element-wise multiply with input
```

**Design rationale**: The multi-scale convolutions (k=3,5,7) capture different morphological features â€” k=3 for sharp QRS peaks, k=5 for P/T wave shapes, k=7 for broader waveform context. Channel attention lets the model learn which scales matter most for each beat type.

#### Model Parameters

| Component | Parameters |
|:----------|:----------|
| MultiScaleBlock 1 | 3 Conv1d + BN + Attention = ~10K |
| MultiScaleBlock 2 | 3 Conv1d + BN + Attention = ~56K |
| MultiScaleBlock 3 | 3 Conv1d + BN + Attention = ~222K |
| Classifier (FC) | 384 Ã— 5 + 5 = 1,925 |
| **Total** | **~487K trainable parameters** |

#### Training Configuration

| Parameter | Value |
|-----------|-------|
| Optimizer | AdamW (weight decay regularization) |
| Learning Rate | 3Ã—10â»â´ |
| Batch Size | 256 |
| Epochs | 25 |
| Loss Function | Focal Loss (Î³=2) â€” down-weights easy examples, focuses on hard/rare classes |
| Sampler | WeightedRandomSampler |
| Device | CUDA (T4 GPU) |

#### Performance Metrics

| Metric | Value |
|--------|-------|
| **Final Train Accuracy** | 98.55% |
| **Test Accuracy** | 60.0% |
| **Weighted F1-Score** | 0.68 |
| **Macro AUROC** | 0.7562 |

**Per-class performance:**

| Class | Precision | Recall | F1-Score | Support |
|:-----:|:---------:|:------:|:--------:|:-------:|
| N | 0.82 | 0.62 | 0.71 | 31,964 |
| S | 0.06 | 0.06 | 0.06 | 1,777 |
| V | 0.72 | 0.83 | 0.77 | 2,458 |
| F | 0.02 | 0.55 | 0.04 | 390 |
| Q | 0.80 | 0.59 | 0.68 | 7,445 |

> **Note**: The gap between train (98.55%) and test (60.0%) accuracy indicates overfitting. The S and F classes have very low F1 due to severe class imbalance (only 1,777 and 390 samples respectively vs. 31,964 for N). For screening purposes, the model effectively identifies abnormal rhythms (V-class F1 = 0.77) which are the most clinically significant.

#### Inference Output

| Risk Level | Abnormality Probability (1 âˆ’ P(Normal)) |
|:----------:|:----------------------------------------:|
| **Low** | < 0.35 |
| **Moderate** | 0.35 â€“ 0.69 |
| **High** | â‰¥ 0.70 |

#### Model File
- **File**: `Heart-model.pt` | **Size**: ~2.08 MB | **Format**: PyTorch `state_dict`

---

### 2. Diabetes Risk Model (DiabetesNet)

#### Dataset
- **Source**: [Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) (UCI / NIDDK)
- **Records**: 768 female patients (â‰¥21 years, Pima Indian heritage)
- **Positive Rate**: 34.9% diabetic (268/768)
- **Split**: 80/20 train-test, stratified, `random_state=42`
- **Preprocessing**: StandardScaler normalization on all 8 features

#### Input Features

| # | Feature | Description | Unit | Dataset Mean Â± Std |
|:-:|---------|-------------|------|--------------------|
| 1 | Pregnancies | Number of pregnancies | count | 3.85 Â± 3.37 |
| 2 | Glucose | Fasting plasma glucose (2hr OGTT) | mg/dL | 120.89 Â± 31.97 |
| 3 | Blood Pressure | Diastolic blood pressure | mm Hg | 69.11 Â± 19.36 |
| 4 | Skin Thickness | Triceps skin fold thickness | mm | 20.54 Â± 15.95 |
| 5 | Insulin | 2-hour serum insulin | Î¼U/mL | 79.80 Â± 115.24 |
| 6 | BMI | Body mass index | kg/mÂ² | 31.99 Â± 7.88 |
| 7 | DPF | Diabetes pedigree function (genetic score) | â€” | 0.47 Â± 0.33 |
| 8 | Age | Age of patient | years | 33.24 Â± 11.76 |

#### Architecture â€” Tabular Deep Neural Network

```
Input: (batch, 8) â€” 8 StandardScaler-normalized features
  â”‚
  â”œâ”€â–º Linear(8 â†’ 32) â†’ BatchNorm1d(32) â†’ ReLU â†’ Dropout(0.3)
  â”œâ”€â–º Linear(32 â†’ 16) â†’ ReLU â†’ Dropout(0.2)
  â””â”€â–º Linear(16 â†’ 1)  â†’ Logit output

Inference: Ïƒ(logit) â†’ probability âˆˆ [0, 1]
```

**Total parameters**: 8Ã—32 + 32 + 32 + 32 + 32Ã—16 + 16 + 16Ã—1 + 1 = **833**

#### Training Configuration

| Parameter | Value |
|-----------|-------|
| Optimizer | Adam |
| Learning Rate | 1Ã—10â»Â³ |
| Batch Size | 32 |
| Epochs | 80 |
| Loss Function | BCEWithLogitsLoss (numerically stable binary cross-entropy) |
| Device | CUDA (T4 GPU) |

#### Performance Metrics

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 73.4% |
| **AUROC** | 0.8170 |

**Per-class performance:**

| Class | Precision | Recall | F1-Score | Support |
|:-----:|:---------:|:------:|:--------:|:-------:|
| Non-diabetic (0) | 0.78 | 0.83 | 0.80 | 100 |
| Diabetic (1) | 0.64 | 0.56 | 0.59 | 54 |

> **Note**: AUROC of 0.817 indicates good discriminative ability. Performance is competitive with literature results on this dataset (typically 74â€“79% accuracy).

#### Inference Output

| Risk Level | Probability |
|:----------:|:-----------:|
| **Low** | < 0.35 |
| **Borderline** | 0.35 â€“ 0.69 |
| **Elevated** | â‰¥ 0.70 |

#### Model File
- **File**: `Diabetes-model.pt` | **Size**: ~8.5 KB | **Format**: PyTorch `state_dict`

---

### 3. Parkinson's Voice Risk Model (ParkinsonNet)

#### Dataset
- **Source**: [UCI Parkinson's Disease Dataset](https://archive.ics.uci.edu/ml/datasets/parkinsons) (University of Oxford)
- **Records**: 195 voice recordings from 31 subjects (23 PD, 8 healthy)
- **Positive Rate**: 75.4% Parkinson's (147/195)
- **Split**: 80/20 train-test, stratified, `random_state=42`
- **Preprocessing**: StandardScaler normalization on all 22 features

#### Input Features (22 Voice Biomarkers)

| Group | Features | Description |
|:------|:---------|:------------|
| **Fundamental Frequency** | Fo(Hz), Fhi(Hz), Flo(Hz) | Average, max, min pitch |
| **Jitter (frequency perturbation)** | Jitter(%), Jitter(Abs), RAP, PPQ, DDP | Cycle-to-cycle pitch variation |
| **Shimmer (amplitude perturbation)** | Shimmer, Shimmer(dB), APQ3, APQ5, APQ, DDA | Cycle-to-cycle amplitude variation |
| **Noise** | NHR, HNR | Noise-to-harmonics ratio, harmonics-to-noise ratio |
| **Nonlinear Dynamics** | RPDE, DFA, D2 | Recurrence entropy, fluctuation analysis, correlation dimension |
| **Pitch Entropy** | spread1, spread2, PPE | Fundamental frequency variation measures |

#### Architecture â€” Tabular Deep Neural Network

```
Input: (batch, 22) â€” 22 StandardScaler-normalized voice features
  â”‚
  â”œâ”€â–º Linear(22 â†’ 64) â†’ BatchNorm1d(64) â†’ ReLU â†’ Dropout(0.4)
  â”œâ”€â–º Linear(64 â†’ 32) â†’ ReLU â†’ Dropout(0.3)
  â””â”€â–º Linear(32 â†’ 1)  â†’ Logit output

Inference: Ïƒ(logit) â†’ probability âˆˆ [0, 1]
```

**Total parameters**: 22Ã—64 + 64 + 64 + 64 + 64Ã—32 + 32 + 32Ã—1 + 1 = **3,617**

#### Training Configuration

| Parameter | Value |
|-----------|-------|
| Optimizer | Adam |
| Learning Rate | 1Ã—10â»Â³ |
| Batch Size | 16 |
| Epochs | 120 |
| Loss Function | BCEWithLogitsLoss |
| Device | CUDA (T4 GPU) |

#### Performance Metrics

| Metric | Value |
|--------|-------|
| **Test Accuracy** | 97.4% |
| **AUROC** | 0.9931 |

**Per-class performance:**

| Class | Precision | Recall | F1-Score | Support |
|:-----:|:---------:|:------:|:--------:|:-------:|
| Healthy (0) | 0.91 | 1.00 | 0.95 | 10 |
| Parkinson's (1) | 1.00 | 0.97 | 0.98 | 29 |

> **Note**: Outstanding performance but evaluated on only 39 test samples. The small test set means confidence intervals are wide. Results should be validated on larger, independent datasets before any clinical consideration.

#### Audio Feature Extraction Pipeline

For uploaded `.wav` files, **librosa** extracts all 22 UCI-compatible features in real-time:

```
WAV file (any sample rate)
  â”‚
  â”œâ”€â–º librosa.load(sr=22050)           â€” resample to standard rate
  â”‚
  â”œâ”€â–º librosa.pyin(fmin=50, fmax=600)  â€” fundamental frequency (F0) estimation
  â”‚     â””â”€â–º Fo(Hz), Fhi(Hz), Flo(Hz)
  â”‚
  â”œâ”€â–º Period analysis (1/F0)            â€” pitch perturbation
  â”‚     â””â”€â–º Jitter(%), Jitter(Abs), RAP (3-pt), PPQ (5-pt), DDP
  â”‚
  â”œâ”€â–º librosa.feature.rms()            â€” amplitude envelope
  â”‚     â””â”€â–º Shimmer, Shimmer(dB), APQ3 (3-pt), APQ5 (5-pt), APQ (11-pt), DDA
  â”‚
  â”œâ”€â–º librosa.effects.harmonic()       â€” harmonic/noise separation
  â”‚     â””â”€â–º NHR, HNR
  â”‚
  â”œâ”€â–º Nonlinear dynamics               â€” complexity measures
  â”‚     â”œâ”€â–º RPDE (recurrence period density entropy)
  â”‚     â”œâ”€â–º DFA (detrended fluctuation analysis)
  â”‚     â””â”€â–º D2 (correlation dimension approximation)
  â”‚
  â””â”€â–º Pitch entropy                    â€” F0 distribution analysis
        â””â”€â–º spread1, spread2, PPE
```

#### Inference Output

| Risk Level | Probability |
|:----------:|:-----------:|
| **Stable** | < 0.35 |
| **Mild** | 0.35 â€“ 0.69 |
| **High** | â‰¥ 0.70 |

#### Model File
- **File**: `Parkinson-model.pt` | **Size**: ~20 KB | **Format**: PyTorch `state_dict`

---

## ğŸ¤– LLM Integration & Prompt Engineering

### System Prompt Design

The Gemini LLM operates under a carefully crafted system prompt with strict medical safety guardrails:

| Prompt Section | Purpose |
|:---------------|:--------|
| **Role Definition** | "You are an AI Health Screening Assistant" â€” establishes screening-only context |
| **Data Collection Protocol** | Asked to collect in small groups (2â€“3 questions) with explanations of WHY each value is needed |
| **MODEL_INPUT Format** | Exactly specifies the structured output format the backend parser expects |
| **Result Explanation** | Rules for presenting MODEL_OUTPUT: empathetic, clear, non-diagnostic language |
| **Safety Rules** | Never diagnose, never claim certainty, always recommend professional consultation |

### Model Fallback Chain

The system automatically cycles through 3 Gemini models to handle API rate limits:

```
gemini-1.5-flash (fastest, lowest cost)
    â”‚ 429 error?
    â–¼
gemini-1.5-pro (highest quality)
    â”‚ 429 error?
    â–¼
gemini-2.0-flash (latest generation)
    â”‚ 429 error?
    â–¼
Graceful error message to user
```

Each retry includes a 2-second delay. Non-rate-limit errors are returned immediately.

---

## System Flow

```
User opens Streamlit UI (localhost:8501)
          â”‚
          â–¼
Assistant greets user, begins medical intake
          â”‚
          â–¼ (conversational loop â€” 2-3 questions per turn)
User provides: age, gender, symptoms,
  diabetes biomarkers, uploads ECG/voice files
          â”‚
          â–¼
LLM outputs <MODEL_INPUT> block with all collected values
          â”‚
          â–¼
Backend parses MODEL_INPUT â†’ runs 3 PyTorch models:
  â”œâ”€â”€ ECGNet      â†’ cardiac_risk   (low / moderate / high)
  â”œâ”€â”€ DiabetesNet â†’ metabolic_risk (low / borderline / elevated)
  â””â”€â”€ ParkinsonNet â†’ motor_risk    (stable / mild / high)
          â”‚
          â–¼
Backend computes triage level + builds <MODEL_OUTPUT>
          â”‚
          â–¼
LLM receives <MODEL_OUTPUT> â†’ explains findings empathetically
          â”‚
          â–¼
User sees screening report with actionable recommendations
```

---

## Project Structure

```
capstone/
â”œâ”€â”€ app.py                     # FastAPI backend â€” orchestration, endpoints, inference pipeline
â”œâ”€â”€ requirements.txt           # Python dependencies (14 packages)
â”œâ”€â”€ .env                       # API keys (GEMINI_API_KEY) â€” NOT committed to git
â”œâ”€â”€ .gitignore                 # Excludes .env, venv, __pycache__, .DS_Store
â”‚
â”œâ”€â”€ Heart-model.pt             # Pretrained ECGNet weights (~2.08 MB, ~487K params)
â”œâ”€â”€ Diabetes-model.pt          # Pretrained DiabetesNet weights (~8.5 KB, 833 params)
â”œâ”€â”€ Parkinson-model.pt         # Pretrained ParkinsonNet weights (~20 KB, 3,617 params)
â”œâ”€â”€ models.ipynb               # Jupyter notebook â€” training code for all 3 models
â”‚
â”œâ”€â”€ inference/                 # Model inference modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ heart.py               # ECGNet architecture + ECG signal processing (238 lines)
â”‚   â”œâ”€â”€ diabetes.py            # DiabetesNet architecture + feature normalization (123 lines)
â”‚   â””â”€â”€ parkinson.py           # ParkinsonNet architecture + WAV feature extraction (431 lines)
â”‚
â”œâ”€â”€ chat/                      # LLM chat modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ groq_client.py         # Gemini LLM client + system prompt + fallback chain (169 lines)
â”‚   â””â”€â”€ parser.py              # MODEL_INPUT/OUTPUT parsing + triage logic (141 lines)
â”‚
â”œâ”€â”€ ui/                        # Frontend
â”‚   â””â”€â”€ streamlit_app.py       # Streamlit chat interface + file uploads + results (338 lines)
â”‚
â”œâ”€â”€ sample_ecg.csv             # Synthetic ECG test file (10s, 360Hz, normal sinus rhythm)
â”œâ”€â”€ sample_voice.wav           # Synthetic voice test file (5s, 22050Hz, sustained vowel)
â”‚
â”œâ”€â”€ mit-bih-arrhythmia-database-1.0.0.zip  # MIT-BIH raw database (~73 MB)
â”œâ”€â”€ Research papers/           # 49 reference papers covering ECG, diabetes, and Parkinson's
â””â”€â”€ *.pdf                      # Additional individual research papers
```

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+
- Google Gemini API key â€” [Get one free](https://aistudio.google.com/apikey)

### Setup (5 minutes)

```bash
# 1. Clone the repository
git clone https://github.com/Harshgoyal2004/capstone.git
cd capstone

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate    # macOS/Linux
# venv\Scripts\activate     # Windows

# 3. Install dependencies
pip install -r requirements.txt

# 4. Configure API key
echo "GEMINI_API_KEY=your_gemini_api_key_here" > .env

# 5. Start the backend (Terminal 1)
uvicorn app:app --reload --port 8000

# 6. Start the frontend (Terminal 2)
source venv/bin/activate
streamlit run ui/streamlit_app.py --server.port 8501

# 7. Open browser
# Navigate to http://localhost:8501
```

**Expected backend output:**
```
============================================================
Health Screening API - Loading Models...
============================================================
[Heart Model] Loaded from Heart-model.pt on cpu
[Diabetes Model] Loaded from Diabetes-model.pt on cpu
[Parkinson Model] Loaded from Parkinson-model.pt on cpu
============================================================
All models loaded. API ready.
============================================================
```

---

## ğŸ§ª Demo & Sample Test Files

The repository includes ready-to-use synthetic test files for a quick demo:

| File | Description | Format |
|:-----|:------------|:-------|
| `sample_ecg.csv` | 10-second synthetic ECG with normal sinus rhythm (72 bpm) | Single-column CSV, 3600 samples at 360 Hz |
| `sample_voice.wav` | 5-second sustained vowel phonation (150 Hz fundamental + harmonics) | 16-bit mono WAV at 22050 Hz |

### Running the Demo

1. Open **http://localhost:8501**
2. **Upload files** in the sidebar:
   - `sample_ecg.csv` â†’ ECG Recording section
   - `sample_voice.wav` â†’ Voice Recording section
3. **Chat** with the assistant, providing info like:
   > *"I'm a 45-year-old male. Glucose 148, blood pressure 85, skin thickness 33, insulin 150, BMI 33.6, DPF 0.627, no pregnancies. I've uploaded both ECG and voice files."*
4. **View results** â€” all 3 models will run and the assistant will explain findings

### Expected Results with Sample Data

| Model | Synthetic Input | Expected Risk |
|:------|:----------------|:--------------|
| ğŸ’“ Heart | Normal sinus rhythm ECG | **Low** |
| ğŸ©¸ Diabetes | Glucose 148 + BMI 33.6 | **Borderline** |
| ğŸ§  Parkinson | Clean synthetic vowel | **Varies** (depends on extracted features) |

---

## Usage Guide

### 1. Start the Conversation
Type a greeting in the chat. The assistant will begin the health screening intake.

### 2. Answer Questions
The assistant will ask for:
- Basic info (age, gender, symptoms)
- Diabetes biomarkers (glucose, blood pressure, BMI, etc.)
- Whether you have an ECG file or voice recording to upload

### 3. Upload Files (Optional)
Use the sidebar to upload:
- **ECG file** (.csv) â€” single-column or multi-column waveform data at any sample rate
- **Voice file** (.wav, .mp3, .flac, .ogg) â€” sustained vowel phonation recording

### 4. Receive Results
Once all data is collected, the system will:
1. Run all three PyTorch models simultaneously
2. Generate individual risk assessments with probabilities
3. Compute automated triage level
4. Provide an empathetic explanation with personalized recommendations

---

## ğŸ“¡ API Reference

### `POST /chat`

Send a conversation and receive the assistant's response with optional model results.

**Request Body:**
```json
{
  "messages": [
    {"role": "user", "content": "Hello"},
    {"role": "assistant", "content": "Welcome!"},
    {"role": "user", "content": "I'm 45 years old, glucose 148..."}
  ],
  "ecg_file_path": "/tmp/health_screening_uploads/ecg.csv",
  "voice_file_path": "/tmp/health_screening_uploads/voice.wav"
}
```

**Response (without model results):**
```json
{
  "response": "Thank you for sharing! Can you also tell me your BMI?",
  "model_results": null
}
```

**Response (with model results â€” when `<MODEL_INPUT>` is detected):**
```json
{
  "response": "Here are your screening results...",
  "model_results": {
    "cardiac_risk": "low",
    "metabolic_risk": "borderline",
    "motor_risk": "stable",
    "triage": "routine",
    "heart": {"probability": 0.1234, "risk_level": "low", "num_beats_analyzed": 8},
    "diabetes": {"probability": 0.5621, "risk_level": "borderline"},
    "parkinson": {"probability": 0.2103, "risk_level": "stable"}
  }
}
```

### `POST /upload`

Upload ECG (.csv) or voice (.wav/.mp3/.flac/.ogg) files.

**Request**: `multipart/form-data` with `file` field

**Response:**
```json
{
  "file_path": "/tmp/health_screening_uploads/ecg.csv",
  "filename": "ecg.csv",
  "file_type": "ecg"
}
```

### `GET /health`

Health check endpoint.

**Response:** `{"status": "healthy", "models_loaded": true}`

---

## Data Collection Protocol

The LLM collects data through natural conversation and outputs a structured block when all information is gathered:

```xml
<MODEL_INPUT>
age: 45
gender: male
symptoms: occasional chest pain, fatigue

pregnancies: 0
glucose: 120
blood_pressure: 80
skin_thickness: 20
insulin: 85
bmi: 28.5
dpf: 0.45
age_diabetes: 45

ecg_file: provided
voice_file: provided
</MODEL_INPUT>
```

The parser (`chat/parser.py`) uses regex to extract the block, splits on newlines, and builds a dict from `key: value` pairs. Missing/unknown values default to `0.0`.

---

## Risk Assessment & Triage

### Individual Risk Levels

| Model | Low Risk | Moderate Risk | High Risk |
|:------|:---------|:-------------|:---------|
| **Heart (ECGNet)** | < 0.35 | 0.35 â€“ 0.69 | â‰¥ 0.70 |
| **Diabetes (DiabetesNet)** | < 0.35 (low) | 0.35 â€“ 0.69 (borderline) | â‰¥ 0.70 (elevated) |
| **Parkinson (ParkinsonNet)** | < 0.35 (stable) | 0.35 â€“ 0.69 (mild) | â‰¥ 0.70 (high) |

### Triage Determination

| Triage Level | Condition | Action |
|:------------:|-----------|--------|
| ğŸ”´ **priority_review** | Any single risk is **high/elevated** | Immediate professional consultation recommended |
| ğŸŸ¡ **recommended_check** | Two or more risks are **moderate/borderline/mild** | Schedule follow-up appointment |
| ğŸŸ¢ **routine** | All other cases | Continue regular health monitoring |

### MODEL_OUTPUT Format

```xml
<MODEL_OUTPUT>
cardiac_risk: moderate (prob: 0.4521)
metabolic_risk: low (prob: 0.3376)
motor_risk: stable (prob: 0.1203)
triage: routine
</MODEL_OUTPUT>
```

---

## ğŸ”Š Signal Processing Deep Dive

### ECG Processing Pipeline

| Step | Method | Parameters |
|:-----|:-------|:-----------|
| **Bandpass Filter** | Butterworth (4th order) | Passband: 0.5â€“40 Hz |
| **R-Peak Detection** | `scipy.signal.find_peaks` | Min distance: 180 samples (0.5s), height: mean + 0.5Ïƒ |
| **Beat Segmentation** | Fixed window around R-peak | 108 pre + 144 post = 252 samples |
| **Fallback** | Center-padding | If no peaks detected, uses middle of signal |

### Voice Feature Extraction

| Algorithm | Library | Output Features |
|:----------|:--------|:----------------|
| **pYIN F0 estimation** | librosa | Fo, Fhi, Flo |
| **Period perturbation** | custom NumPy | Jitter(%), Jitter(Abs), RAP, PPQ, DDP |
| **RMS amplitude analysis** | librosa | Shimmer, Shimmer(dB), APQ3, APQ5, APQ, DDA |
| **Harmonic separation** | librosa | NHR, HNR |
| **Recurrence analysis** | custom NumPy | RPDE (entropy of recurrence periods) |
| **Detrended fluctuation** | custom NumPy | DFA (scaling exponent Î±) |
| **Correlation dimension** | custom NumPy | D2 (Grassberger-Procaccia algorithm) |
| **Pitch entropy** | custom NumPy | spread1, spread2, PPE |

---

## ğŸ“š Research Papers

The `Research papers/` directory contains **49 reference papers** spanning three disease domains:

| Domain | Count | Key Topics |
|:-------|:------|:-----------|
| **Cardiac / ECG** | ~18 | Arrhythmia detection, transformer models, attention mechanisms, CNN architectures |
| **Diabetes** | ~14 | Feature selection, ensemble methods, deep learning, explainable AI |
| **Parkinson's** | ~17 | Voice analysis, wearable sensors, multimodal diagnosis, deep learning detection |

---

## ğŸ”® Future Improvements

| Area | Enhancement |
|:-----|:------------|
| **Heart Model** | Address overfitting gap (98% train â†’ 60% test) with stronger regularization, data augmentation, or transfer learning |
| **Heart Model** | Improve S-class and F-class detection with SMOTE or focused sampling |
| **Diabetes Model** | Validate on larger, multi-ethnic datasets (not just Pima Indian heritage) |
| **Parkinson Model** | Validate on larger independent voice datasets; current test set is only 39 samples |
| **Feature Extraction** | Replace approximated RPDE/DFA/D2 with clinical-grade implementations |
| **LLM** | Migrate to Google `google.genai` SDK (current `google.generativeai` is deprecated) |
| **Deployment** | Dockerize backend + frontend for one-command deployment |
| **Security** | Add authentication, rate limiting, and input sanitization |
| **Testing** | Add unit tests for inference modules and integration tests for the API |

---

## Limitations & Disclaimer

> âš ï¸ **This is an AI screening tool, NOT a medical device.**

- **Not a diagnosis**: Results are preliminary screening indicators only
- **Not FDA-approved**: This system has not been validated for clinical use
- **Dataset limitations**: Models were trained on specific populations (MIT-BIH for heart, Pima Indians for diabetes, UCI dataset for Parkinson's) and may not generalize to all demographics
- **Small test sets**: The Parkinson's model was evaluated on only 39 samples
- **Class imbalance**: The heart model shows poor performance on rare classes (S-class F1 = 0.06, F-class F1 = 0.04)
- **Feature extraction**: Voice analysis features (RPDE, DFA, D2) are computational approximations, not clinical-grade measurements
- **LLM dependency**: Result explanations depend on Gemini API availability and quality
- **Always consult healthcare professionals** for medical advice, diagnosis, and treatment

---

## License

This project is for **educational and research purposes only**. Not intended for clinical deployment.

---

## Acknowledgments

- **[MIT-BIH Arrhythmia Database](https://physionet.org/content/mitdb/1.0.0/)** â€” PhysioNet (Moody GB, Mark RG)
- **[Pima Indians Diabetes Dataset](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database)** â€” UCI / NIDDK
- **[UCI Parkinson's Disease Dataset](https://archive.ics.uci.edu/ml/datasets/parkinsons)** â€” University of Oxford (Max Little)
- **[Google Gemini API](https://ai.google.dev)** â€” Large Language Model
- **[PyTorch](https://pytorch.org)** â€” Deep Learning Framework
- **[librosa](https://librosa.org)** â€” Audio Analysis Library
- **[Streamlit](https://streamlit.io)** â€” Frontend Framework
- **[FastAPI](https://fastapi.tiangolo.com)** â€” Backend Framework
]]>
